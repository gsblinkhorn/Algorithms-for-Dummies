{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring Data\n",
    "\n",
    "Before you can do anything with most data, you must structure it in some manner so that you can begin to see what the data contains(an, sometimes, what it doesn't). Python provides access to a number of organizational structures for data, including stacks, queues and dictionaries. \n",
    "\n",
    "You need to consider the structural requirements for the data you use with your algorithms; the better you can see and understand the content through structure formatting, the easier it becomes to perform algorithm-based tasks successfully. Trying to impose form on humans rarely works and generally results in frustration that makes using the algorithm even harder, so structure imposed through data manipulation becomes even more important.\n",
    "\n",
    "#### When working with mulitple data sources, you must:\n",
    "- Determine whether both datasets contain all the required data\n",
    "- Check both datasets for data type issues\n",
    "- Ensure that all datasets place the same meaning on data elements\n",
    "- Verify the data attributes\n",
    "\n",
    "The more time you spend verifying the compatibility of data from each of the sources you want to use for a dataset, the less likely you are to encounter problems when working with an algorithm.\n",
    "\n",
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering the Need for Remediation\n",
    "\n",
    "After you find problems with your dataset, you need to remediate it so that the dataaset works properly wih the algorithms you use. For example, when working with conflicting data type, you must change the data types of each data sources so that they match and then create the single data source used with the algorithm. Data duplication and missing values are two very common data problems, but remediation can be necessary due to a host of reasons (inconsistent data entry, misspellings, out-of-range values, etc.). \n",
    "\n",
    "Often, you become aware of a problem by running the algorithm and noting that the results are skewed in some way or that the algorithm doesn't work at all (even if it worked on a subset of the data). When in doubt, check your data for potential remediation needs.\n",
    "\n",
    "### Dealing with Data Duplication\n",
    "\n",
    "Duplicated data can happen for a variety of reasons during the remediation process, and can unfairly weight the output of any algorithm that you're using. The pandas package makes it easy to remove duplicated data. The `drop_duplicates` function removes the duplicate records found in rows 4 and 6 in the below example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  0  0  0\n",
      "1  0  2  3\n",
      "2  0  3  4\n",
      "3  0  5  1\n",
      "4  0  0  0\n",
      "5  1  2  2\n",
      "6  0  0  0 \n",
      "\n",
      "   A  B  C\n",
      "0  0  0  0\n",
      "1  0  2  3\n",
      "2  0  3  4\n",
      "3  0  5  1\n",
      "5  1  2  2\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [0,0,0,0,0,1,0],\n",
    "                   'B': [0,2,3,5,0,2,0],\n",
    "                   'C': [0,3,4,1,0,2,0]})\n",
    "print(df, \"\\n\")\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values\n",
    "\n",
    "Missing values can also skew the results of an algorithm't output. In fact, they can cause some algorithms to react oddly or even raise an error. The point is that missing values cause problems with your data, so you need to remove them. \n",
    "\n",
    "Options for addressing this issue include:\n",
    "- Simply setting missing values to a standard value, such as 0 for ints\n",
    "- Using the mean of all the values instead of some standard value\n",
    "\n",
    "The `fillna` functions enables you to get rid of the missing values whether they're not a number (NAN) or simply missing (None). You can supply the missing data in a number of forms - this example relies on a series that contains the mean for each seperate column of data.\n",
    "\n",
    "#### Mean Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame\n",
      "       A  B    C\n",
      "0     0  1  NaN\n",
      "1     0  2    3\n",
      "2     1  3    4\n",
      "3  None  4    1 \n",
      "\n",
      "Mean of Each Column\n",
      " A    0\n",
      "B    2\n",
      "C    2\n",
      "dtype: int64 \n",
      "\n",
      "Mean-Replacement\n",
      "    A  B  C\n",
      "0  0  1  2\n",
      "1  0  2  3\n",
      "2  1  3  4\n",
      "3  0  4  1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': [0,0,1,None],\n",
    "                   'B': [1,2,3,4],\n",
    "                   'C': [np.NAN,3,4,1]}, dtype=int)\n",
    "print(\"Original DataFrame\\n\", df, \"\\n\")\n",
    "\n",
    "values = pd.Series(df.mean(), dtype=int) # ensures values is the same datatype as the original DataFrame\n",
    "print(\"Mean of Each Column\\n\", values, \"\\n\")\n",
    "\n",
    "df = df.fillna(values)\n",
    "print(\"Mean-Replacement\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Piling Data in Order\n",
    "\n",
    "Python provides a number of storage methodologies, and both NumPy and Pandas provide storage alternatives that might consider when working through various data structures. A common problem of data storage isn't just the fact that you need to store the data, but that you must store it in a particular order so that you can access it when necessary. The following sections describe the standard Python methods for ensuring orderly data storage that let you have a specific processing arrangement.\n",
    "\n",
    "### Ordering in Stacks\n",
    "\n",
    "A *stack* provides last in/first out (LIFO) data storage. Recursive function calls, for example, are placed on a stack, such that each new call goes on the top of the stack until the base case is reached, then the function calls are *popped* off the stack as they resolve down to the original function call. The NumPy package provides an actual stack implementation, and Pandas associates stacks with objects such as DataFrames. \n",
    "\n",
    "To demonstrate the functionality of a stack, an example implementation is given below. The example ensures that the stack maintains the integrity of the data and works with it in the order you expect.\n",
    "\n",
    "**Important Tip:** The below example is implemented using a Python list - from an algorithm perspective, lists often don't perform well because they store the list elements in computer memory and access them using an index and *memory pointer*, a number that provides the memory address of the data. When your application makes a data request, the list scans through all of its items, which is even slower. When data is scattered across your computer's memory, lists must gather the data from each location indiviudal, whcih slows access even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack is empty! \n",
      "\n",
      "Push values onto the stack\n",
      "Current Stack:\n",
      "0: 5\n",
      "1: 10\n",
      "2: 4\n",
      "3: 6\n",
      "4: 2\n",
      "\n",
      "Popping:  5\n",
      "Current Stack:\n",
      "0: 10\n",
      "1: 4\n",
      "2: 6\n",
      "3: 2\n",
      "\n",
      "Popping:  10\n",
      "Popping:  4\n",
      "Current Stack:\n",
      "0: 6\n",
      "1: 2\n",
      "\n",
      "Popping:  6\n",
      "Popping:  2\n",
      "Stack is empty!\n"
     ]
    }
   ],
   "source": [
    "class Stack:\n",
    "    stack = None\n",
    "    stackSize = 10\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.stack = []\n",
    "        self.stackSize = size\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"Current Stack:\\n\"\n",
    "        \n",
    "        if len(self.stack) > 0:\n",
    "            for i, item in enumerate(self.stack[::-1]):\n",
    "                result += (str(i) + \": \" + str(item) + \"\\n\")\n",
    "        else:\n",
    "            return \"Stack is empty!\"\n",
    "        \n",
    "        return result        \n",
    "        \n",
    "    def push(self, value):\n",
    "        if len(self.stack) < self.stackSize:\n",
    "            self.stack.append(value)\n",
    "        else:\n",
    "            print(\"Stack is full!\")\n",
    "            \n",
    "    def pop(self):\n",
    "        if len(self.stack) > 0:\n",
    "            print(\"Popping: \", self.stack.pop())\n",
    "        else:\n",
    "            print(\"Stack is empty!\")\n",
    "            \n",
    "myStack = Stack(10)\n",
    "print(myStack, \"\\n\")\n",
    "\n",
    "print(\"Push values onto the stack\")\n",
    "myStack.push(2)\n",
    "myStack.push(6)\n",
    "myStack.push(4)\n",
    "myStack.push(10)\n",
    "myStack.push(5)\n",
    "print(myStack)\n",
    "\n",
    "myStack.pop()\n",
    "print(myStack)\n",
    "\n",
    "myStack.pop()\n",
    "myStack.pop()\n",
    "print(myStack)\n",
    "\n",
    "myStack.pop()\n",
    "myStack.pop()\n",
    "print(myStack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering in Queues\n",
    "Unlike stacks, *queues* are first in/first out (FIFO) data structures. Both NumPy and Pandas offer implementations of the queue structure, but you can also leverage Python's built-in queue implementation using `import queue`. Rather than implementing our own queue, we'll use Python's queue to demonstrate how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue Empty:  True\n",
      "\n",
      "Putting values in the queue: 2, 10, 5\n",
      "Queue Full:  True\n",
      "\n",
      "Popping:  2\n",
      "Queue Full:  False\n",
      "\n",
      "Popping:  10\n",
      "Popping:  5\n",
      "Queue Empty:  True\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "myQ = queue.Queue(3)\n",
    "\n",
    "print(\"Queue Empty: \", myQ.empty())\n",
    "\n",
    "print(\"\\nPutting values in the queue: 2, 10, 5\")\n",
    "myQ.put(2)\n",
    "myQ.put(10)\n",
    "myQ.put(5)\n",
    "print(\"Queue Full: \", myQ.full())\n",
    "\n",
    "print(\"\\nPopping: \", myQ.get())\n",
    "print(\"Queue Full: \", myQ.full())\n",
    "\n",
    "print(\"\\nPopping: \", myQ.get())\n",
    "print(\"Popping: \", myQ.get())\n",
    "print(\"Queue Empty: \", myQ.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Data Using Dictionaries\n",
    "Creating a `dictionary` is much like working with a `list`, except that you must now define a key and value pair. The great advantage of this data structure is that dictionaries can quickly provide access to specific data items using the key.\n",
    "\n",
    "**Key Limitations:**\n",
    "- The key must be unique - if a duplicate key is used, the value in the second entry overwrites the value in the original entry\n",
    "- The key must be immutable\n",
    "\n",
    "Python dictionaries are the software implementation of a data structure called a *hash table*, an array that maps keys to values. Dictionaries are a bit like individual tables within a database. You can update, add, and delete records to a dictionary. The `update` function can overwrite or add new entries to the dictionary. The following example helps demonstrate how dictionaries work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarah's favorite color is: Yellow\n",
      "The keys are: dict_keys(['Sam', 'Amy', 'Sarah'])\n",
      "\n",
      "Demonstrating key duplication - colors['Sarah'] = 'Purple':\n",
      "Sarah's favorite color is: Purple\n",
      "\n",
      "Demonstrating value updates - colors.update({'Sarah':'Black'}):\n",
      "Sarah's favorite color is: Black\n",
      "\n",
      "Demonstrating adding new values - colors.update({'Mark':'Orange'}):\n",
      "Mark's favorite color is: Orange\n",
      "\n",
      "Values can be deleted as well - del colors['Sarah']:\n",
      "{'Sam': 'Blue', 'Amy': 'Red', 'Mark': 'Orange'}\n"
     ]
    }
   ],
   "source": [
    "colors = {'Sam':'Blue',\n",
    "          'Amy':'Red',\n",
    "          'Sarah':'Yellow'}\n",
    "\n",
    "print('Sarah\\'s favorite color is:', colors['Sarah'])\n",
    "print('The keys are:', colors.keys())\n",
    "\n",
    "print(\"\\nDemonstrating key duplication - colors['Sarah'] = 'Purple':\")\n",
    "colors['Sarah'] = 'Purple'\n",
    "print('Sarah\\'s favorite color is:', colors['Sarah'])\n",
    "\n",
    "\n",
    "print(\"\\nDemonstrating value updates - colors.update({'Sarah':'Black'}):\")\n",
    "colors.update({'Sarah':'Black'})\n",
    "print('Sarah\\'s favorite color is:', colors['Sarah'])\n",
    "\n",
    "print(\"\\nDemonstrating adding new values - colors.update({'Mark':'Orange'}):\")\n",
    "colors.update({'Mark':'Orange'})\n",
    "print('Mark\\'s favorite color is:', colors['Mark'])\n",
    "\n",
    "print('\\nValues can be deleted as well - del colors[\\'Sarah\\']:')\n",
    "del colors['Sarah']\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Trees\n",
    "Using trees helps you organize data quickly and find it in a shorter time than using other data storage techniques. You commonly find trees used for search and sort routines, but they have many other purposes as well.\n",
    "\n",
    "### Tree Definitions\n",
    "- *node* - each item (or data value) which makes up the tree\n",
    "- *root node* - provides the starting point for the various kinds of processing you perform\n",
    "- *leaf node* - a node with no children; an end point for the tree\n",
    "- *links* - how nodes are connected to one another\n",
    "- *trees* - the combination of nodes and links which forms the data structure\n",
    "\n",
    "### Kinds of Trees\n",
    "**Balanced Trees:** A kind of tree that maintains a balanced structure through reorganization so that it can provide reduced access times. The number of elements on the left side differs from the number of elements on the right side by at most one. One example of a balanced tree is the AVL Tree, a balanced binary search tree.\n",
    "\n",
    "**Unbalanced Trees:** A tree that places new data items wherever necessary in the tree without regard to balance. This method of adding items makes building the tree faster but reduces access speed when searching or sorting.\n",
    "\n",
    "**Heaps:** A sophisticated tree that allows data insertions into the tree structure. The use of data insertion makes sorting faster. You can further classify these trees as max heaps and min heaps, depending on the tree's capability to immediately provide the maximum or minimum value present in the tree.\n",
    "\n",
    "## Representing Relations in Graphs\n",
    "*Graphs* are another form of common data structure - they are a sort of tree extension; as with trees, you have nodes that connect to each other to create relationships, but a graph node can have more than one or two connections. \n",
    "\n",
    "Most developers use dictionaries to build graphs - using a dictionary makes building the graph easy because the key is the node name and the values are the connections for that node. Below you can see an example graph implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Node  A\n",
      "Path so far  ['B']\n",
      "Checking Node  B\n",
      "Checking Node  F\n",
      "Path so far  ['B', 'A']\n",
      "Checking Node  E\n",
      "Path so far  ['B', 'A', 'F']\n",
      "Ending\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'A', 'F', 'E']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = {'A': ['B', 'F'],\n",
    "         'B': ['A', 'C'],\n",
    "         'C': ['B', 'D'],\n",
    "         'D': ['C', 'E'],\n",
    "         'E': ['D', 'F'],\n",
    "         'F': ['E', 'A']}\n",
    "\n",
    "def find_path(graph, start, end, path=[]):\n",
    "    path = path + [start]\n",
    "    \n",
    "    if start == end:\n",
    "        print('Ending')\n",
    "        return path\n",
    "    \n",
    "    for node in graph[start]:\n",
    "        print(\"Checking Node \", node)\n",
    "        \n",
    "        if node not in path:\n",
    "            print(\"Path so far \", path)\n",
    "            newPath = find_path(graph, node, end, path)\n",
    "            if newPath:\n",
    "                return newPath\n",
    "\n",
    "find_path(graph, 'B', 'E')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
